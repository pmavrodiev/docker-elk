 input {
    file {
 		 path => "/usr/share/logstash/job_crawler_logs/spider_jobsch.log"
 		 start_position => "beginning"
 		 mode => "tail"
 		 id => "live_log"
 		 stat_interval => "1 day"
 		 discover_interval => 1
 		 file_completed_action => "log"
 		 file_completed_log_path => "/usr/share/logstash/file_completed/spider_jobsch.log"
     sincedb_path => "/usr/share/logstash/file_completed/spider_jobsch.sdb"
    }
 }

 input {
    file {
 		 path => "/usr/share/logstash/job_crawler_logs/*.gz"
 		 start_position => "beginning"
 		 mode => "read"
 		 id => "rotated_logs"
 		 stat_interval => "1 day"
 		 discover_interval => 1
 		 file_completed_action => "log"
 		 file_completed_log_path => "/usr/share/logstash/file_completed/spider_jobsch_rotated.log"
     sincedb_path => "/usr/share/logstash/file_completed/spider_jobsch_rotated.sdb"
    }
 }

# input {
#  generator {
#    lines => ["2020-03-12 22:00:05,630 - INFO - [jobsch_spider] - Looking for next page href on - page https://www.jobs.ch/en/vacancies/?term=Team%20Leader"]
#    count => 1
#  }
#}

filter {
	dissect {
		mapping => {
			"message" => "%{timestamp}-%{+timestamp}-%{+timestamp}-%{type}-%{}[%{module_name}]%{}	%{msg}"
		}
	}
	mutate {
		strip => ["timestamp", "module_name", "type", "msg"]
	}
	date {
		match => [ "timestamp", "yyyy-MM-dd HH:mm:ss,SSS" ]
	}
	mutate {
		remove_field => [ "timestamp", "host", "message"]
	}
}

 output {
   stdout { codec => rubydebug }
  }

## Add your filters / logstash plugins configuration here

# output {
# 	elasticsearch {
# 		hosts => "elasticsearch:9200"
# 		user => "elastic"
# 		password => "changeme"
# 	}
#}
